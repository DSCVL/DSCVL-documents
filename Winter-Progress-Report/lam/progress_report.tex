\documentclass[onecolumn, draftclsnofoot,10pt, compsoc]{IEEEtran}
\hbadness=1000 % suppress warnings
\usepackage{graphicx}
\usepackage{url}
\usepackage{setspace}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{geometry}
\usepackage{longtable}

\geometry{textheight=9.5in, textwidth=7in}

% 1. Fill in these details
\def \CapstoneTeamName{			}
\def \CapstoneTeamNumber{		69}
\def \GroupMemberOne{			Kin-Ho Lam}
\def \CapstoneProjectName{		Depth Sensing with Computer Vision and Lidar}
\def \CapstoneSponsorCompany{	Oregon State University}
\def \CapstoneSponsorPerson{	D. Kevin McGrath}


% 2. Uncomment the appropriate line below so that the document type works
\def \DocType{
	Individual Winter Progress Report
}

\newcommand{\NameSigPair}[1]{\par
	\makebox[2.75in][r]{#1} \hfil 	\makebox[3.25in]{\makebox[2.25in]{\hrulefill} \hfill		\makebox[.75in]{\hrulefill}}
	\par\vspace{-12pt} \textit{\tiny\noindent
		\makebox[2.75in]{} \hfil		\makebox[3.25in]{\makebox[2.25in][r]{Signature} \hfill	\makebox[.75in][r]{Date}}}}
% 3. If the document is not to be signed, uncomment the RENEWcommand below
\renewcommand{\NameSigPair}[1]{#1}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\graphicspath{{images/}}
\begin{document}
	\begin{titlepage}
		\pagenumbering{gobble}
		\begin{singlespace}
			\centering
			\includegraphics[height=4cm,natwidth=345,natheight=435]{images/osu_logo.png}
			\hfill 
			% 4. If you have a logo, use this includegraphics command to put it on the coversheet.
			%\includegraphics[height=4cm]{CompanyLogo}   
			\par\vspace{.2in}
			\centering
			\scshape{
				\huge Senior Design Capstone \DocType \par
				{\large\today}\par
				\vspace{.5in}
				\textbf{\Huge\CapstoneProjectName}\par
				\vfill
				{\large Prepared for}\par
				\Huge \CapstoneSponsorCompany\par
				\vspace{5pt}
				{\Large\NameSigPair{\CapstoneSponsorPerson}\par}
				{\large Prepared by }\par
				Group\CapstoneTeamNumber\par
				% 5. comment out the line below this one if you do not wish to name your team
				\CapstoneTeamName\par 
				\vspace{5pt}
				{\large
					\NameSigPair{\GroupMemberOne}\par
				}
				\vspace{20pt}
			}
			\begin{abstract}  
 				Depth Sensing with Computer Vision and Lidar proposes combining computer vision and lidar to create a reliable depth sensor.
				This document details its project member's progress toward a final design.
			\end{abstract}     
		\end{singlespace}
	\end{titlepage}
\section{Table of Contents}
\tableofcontents
\bibliographystyle{IEEEtran}
\bibliography{ref}
\clearpage

\begin{singlespace}
	\section{Definitions}
		\subsection{IR}\label{def:IR}
		IR refers to the infrared light spectrum.

		\subsection{IR Depth Sensor}\label{def:depthsensor}
		A device that calculates distances by emitting infrared patterns. 
		
		\subsection{lidar}\label{def:lidar}
		Light Detection And Ranging - A method that uses lasers to measure distance
		
		\subsection{Microsoft Kinect}\label{def:kinect}
		A product that uses an IR Depth sensor to measure distances.
		Referred to as a benchmark comparison for the purpose of this project.
		
		\subsection{Logitech Brio Webcam}\label{def:brio}
		Web-cam used for this project made by Logitech. \cite{logitech}
		
		\subsection{RPLidar A1}\label{def:rplidar}
		A budget lidar device used for this project made by Slamtec. \cite{slamtec}

		\subsection{Leddar M16}\label{def:m16}
		A solid-state lidar device made by Leddar.
		This is the primary lidar device we shall be using.

		\subsection{Computer Vision }\label{def:vision}
		The methods for acquiring, processing, analyzing, and classifying digital images and extracting information.

		
	\section{Project Purpose}
		Commercial infrared-based depth sensors such as the model used in Microsoft's Kinect can quickly calculate distances in indoor scenarios.
		However, IR depth sensors can be confused by other infrared emitters such as other IR depth sensors or natural sunlight.
		For these reasons, IR depth sensors cannot be used in self-driving cars, outdoor robots, or any any device that requires high accuracy in varying conditions.


		Depth Sensing with Computer Vision and lidar proposes combining the power of computer vision with the reliability of lidar technology.
		lidar uses a pulsing laser to measure relative distance.
		The lidar unit we're going to be using is called the RPLidar A1. \ref{rplidar}
		We'll be combining this with a high-end Logitech Brio Webcam. \ref{brio}
		The completed project shall present a conglomeration of computer-vision based object recognition married to the high-accuracy of lidar.
		The Logitech Brio webcam provides two-dimensional image but lacks depth perception.
		The RPLidar A1 Lidar provides accurate depth measurement in a horizontal dimension but lacks vertical depth sensing.
		Combining the functionality of both devices to get accurate three-dimensional depth sensing presents a unique engineering challenge.
		This project proposes bridging the utility of both devices by securing them in stationary positions, then using software to combine their outputs.
		This involves using the RPLidar's library to get depth sensing information, and using computer vision to recognize objects.

	\section{Current State}
		\subsection{Computer Vision}
			The computer vision and object recognition component for this project is in a completed state.
			Using a pre-trained Tensorflow model, our project is now able to accurately outline and label over 90 subjects as they come into view of the webcam.
			
	\section{Partner Evaluation}
		My partner, Lucian Tamno, displays excellent work ethic, enthusiasm, dedication to our project, and an absolute commitment to do his best.
		I am very proud of my partner's performance, and I am confident we can achieve our project goals despite our late project start.
		Lucian's professional demeanor sets him apart and above many of our peers, as he is able to self-assign tasks and quickly comprehend technical concepts.
		I believe our individual experiences in professional working environments facilitates our team chemistry and communication.
		It is extremely refreshing to witness my project partner assume responsibilities and take ownership of his role.
		Where others may attribute their failures to others or blame external influences, Lucian displays level-headed and long-term thinking that will benefit him in his professional career.
		While we sometimes struggle with a small language barrier, I am certain this won't be an issue as we learn each other's mannerisms.
		I believe we have a lot to teach each other, and I look forward to our final term as we build this project to reflect our best efforts.

	\section{Conclusion}
	

	\clearpage

	\section{Ten-Week Term Retrospective}
		\begin{longtable}{|l|p{0.3\linewidth}|p{0.3\linewidth}|p{0.3\linewidth}|}\hline \textbf{Week} & \textbf{Positives} & \textbf{Deltas} & \textbf{Actions}\\\hline
		1 	&
			-
			&
				Kim says we're moving too slowly compared to previous teams
				In my opinion making a website is a far simpler task than writing code that performs analysis  and aggregates data in a system that is unproven and has never been done before

				Kim don't want us to work on filtering acceptable images even through that is what we stated we would do in our problem statement
				All problem statement drafts focused on filtering acceptable images
				None of our problem statements alluded to focusing on image analysis to interpret aerosol content
			&
				OUR TWO OPTIONS PRESENTED TO US:
				1) Kim wants us to focus on a system to interpret aerosol content in the atmosphere based on images of the horizon, EXIF data from those images, and data from wunderground
				2) (In her view) continue on this image filtering path we have started, overall this current project goal of a filter is not applicable to Aerolyzer

				I believe we have not gone astray. What I have written is relevant in either option.
				I still believe we can accomplish 1). 

				Seems like she gave up on us
				(in my opinion) we are a lower priority given our pace and low confidence in our abilities
				The code I wrote is still relevant. It will still pick out the sky which is still very necessary, it will still need to be used no matter the option we choose.

				I am the only one on Github discussing anything about the project.
				Neither Logan or Daniel have communicated to me that the direction we were going was wrong
				I don't think Kim understands the scope of the code that is necessary for a filter or why a filter is necessary
				I don't think she is reading what I'm documenting on our github or how my code is used.

			\\\hline

		2 	&
			Meeting with kevin over webex last Friday transcribed notes

			May or may not have a partner

			Usable up to 50 meters, 450 spread
			Take feed from normal webcam and overlay Leddar point cloud on video
			With minimum range and maximum range
			Device: Leddar Lydar M16
			Webcam: Logitech Brio webcam

			Most depth cameras don't work well outdoors, light sensors are overwhelmed by ambient light, overlaying point cloud on webcam video may be a way to resolve this problem

			&
			-
			&
			Research Leddar Lydar M16.
			2D Lydar unit, see if I can overlay point cloud on webcam image.
			Ideas to try:
			Research dept/distance sensing fpr 

			\\\hline

		3	&
			Talked with Lucian over email
			Unfortunately this time won't work for him, I want to keep this slot so we can at least talk, I'll leave it to him to find time to talk with you
			Gave him a quick rundown of what I understood the project to be

			He mentioned he was going to write up a problem statement and design document. 
			
			&
			Not sure exactly how to help Lucian writing the documents.
			&
			Don't need ROS (Robot operating system, don't need to use it)

			Camera depth sensor doesnâ€™t work in sunlight, accompany with LIDAR unit

			Use realsense as point of comparison
			\\\hline

		4	&
			Borrowed Logitech brio from Kevin
			Got it working with VLC on Windows 10, set it as capture device.
			&
			Alpha stage of project = visually complete interface 
			Responsive code with placeholders for functionality
			&
			Experimenting with Brio webcam and opencv vision models.
			\\\hline

		5 	&
			Interface design?

			Suggestion: To start, draw red dot on video feed and output
			Construct internal pipeline first
			&
			Lucian and Kevin met in person for our weekly meeting, did not answer webex call so I'm not sure what they discussed.
			&
			Sent Kevin my update + screenshots and sketches of my proposed design.
			\\\hline

		6	&
			Created opencv python script to overlay green box on webcam video feed
			Successfully overlaid pixels on camera output
			Output is stuck on 4:3 resolution, going to work with it now and write code to be scalable, I want to increase ratio to 16:9 sometime, see if it's because I'm running on Linux, try with Lucian's computer later today
			&
			So the algorithmic dilemma I'm struggling with:
			We want to transfer what the lydar detects in physical 3 dimensional space into a 2D representation overlaid on a video.
			Let this white bar I've drawn here represent an offset in the y dimension (2D space in video) and z dimension (3D physical space).
			As we move our point of interest to specified distances, this angle needs to remain constant and our y/z offset needs to grow or shrink accordingly.
			This means our camera and lydar need to be stationary to define some constant angle, once that is done we can just apply some pretty simple math.
			&
			Experiment with background subtraction and opencv SVM to capture human faces.
			\\\hline

		7	&
			Lucian was talking about using some kind of equation in opencv to get distance, I think we need to get a better illustration to see how Kevin envisions us connecting the webcam feed to the data from the lydar
			&
			Sometimes I'm not sure what Lucian means.
			&
			Per my conversation with Kevin, I successfully used a trained SVM cascading front-face model to detect faces, not extremely accurate right now, thinking about using this to get face detection
			Specifically, this is needed because the Lydar will capture objects in an X-Y plane, we need the face detection to have some frame of reference in the Z direction.
			Our midterm progress report due date got pushed back, I drafted and finalized a few sections.
			Lucian wrote the other half.
			\\\hline

		8	&
			Accidently missed our poster critique session, we're going to attend the extra credit session for credit.
			&
			-
			&
			Successfuly implimented a pre-trained Tensorflow object detection model.
			This detects full or partial bodies with very high accuracy.
			After minimal tuning, the machine learning part is effectively done.
			\\\hline

		9	&
			Poster Critique session had the following suggestions: Make sure correct poster format, put figure and captions, put x-y-z scale on main image, change layout, "visually connecting" layout to have presentation flow
			Doesnâ€™t need period at tagline
			Include contact
			Include Client
			&
			-
			&
			Made adjustments to poster design.
			\\\hline

		10	&
			Dead week, we're busy writing the Winter report.
			&
			Lucian accidentally wiped the contents and history of our documents repo.
			Fortunatly I had it cloned on my laptop so nothing was lost.
			&
			Need to discuss work schedule with Kevin and Lucian.
			\\\hline
		\end{longtable}

\end{singlespace}
\end{document}
